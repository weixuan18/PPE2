# Séance 11

## 24 avril 2023
**ZHANG**: Nos scripts pour les dernières démarches ont été bien organisés et fusionnés dans la branche **main**. À l'aide de toutes les informations fournies dans la séance cette semaine, j'ai ainsi travaillé sur la modélisation de sujets avec `Genism` et `LDA`.

Après avoir installé le module `Gensim`, j'ai rencontré une erreur d'incompatibilité entre les modules Python lors de l'importation du module.
```
Numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject

```

En créant et activant un environnement virtuel, j'ai résolu ce problème et importé `Gensim` sans accroc. On est alors tout prêt à explorer la modélisation des motifs. *Petit rappel*: `source myenv/bin/activate` pour activer e-env alors que `deactivate` pour le désactiver.


De plus, j'ai établi un nouveau script `LDA_model.py` tout en créant plussieurs fonctions :
- **charge_xml()**,**charge_json()**,**charge_pickle()**  pour faciliter l'importation de différents types de fichiers et les convertir en listes des documents
- une fonction spécifique **preprocess_documents(docs)** pour pré-entraîner les textes à être utilisés dans la modélisation de sujets
- **train_lda_model()** pour construire notre modèle LDA, un ensemble de paramètres a été mis en place dedans pour guider notre modèle d'entraînement. Une fois le modèle entraîné, nous avons calculé la cohérence moyenne des sujets, un indicateur clé de la qualité de notre modèle.
- pour couronner le tout, une fonction **visualize_lda_model()** pour visualiser les résultats de notre modèle LDA à l'aide de `pyLDAvis`.

## 25 avril 2023
**HUANG** : Les scripts pour le prétraitement de corpus sont tous bien formés. Notamment pour le script de l'analyseur `Stanza`, j'ai découvert qu'il est pas nécessaire de rappeler chaque fois *download* pour le pakage fr. Le script est testé en produisant un xml de sous-corpus et il en sorte que le résultat correspond bien au format pareil que `Spacy`.

En récupérant le script de la version du prof, j'ai obtenu un fichier html qui est capable d'analyser et de présenter les résultats obtenu par l'entraîenement de `LDA`. 

Le fichier *sortie.html* montre à droite les mots (ou je dirais plutôt les segments?) fréquents, mais les premiers rangs sont occupés par les ponctuation telles que *«*, ce qui me pose la question : faut-il créer d'autres fonctions pour ignorer et supprimer ces `mots vides` pour faciliter l'analyse sur les mots vrais (porte du sens) ?

Mon camarade a proposé un entraînement plus complet pour l'analyse, en comparant les deux sorties html, il me semble que ce serait intéressant de voir les fonctions précises et les différences.

## 28 avril 2023
**HUANG** : En posant les questions concernant les fonctions de `LDA`, nous nous somme dirigés vers les étapes suivantes :

Choix entre POS ou Stopwords : on suppose que, en choisissant les catégories de POS (NOUN, PROPN, ADJ), nous serons parvenus à éviter la pollution des mots vides.

En réecrivant le script run_lda.py, j'ai choisi les trois catégories de POS (mentionnées ci-dessus) comme sources pour l'analyse. Il en sorte que le résultat est plus précis mais cela nous amène à deux questions :

1. La taille pertinente de corpus : j'ai au début essayé un corpus de 3 jours avec une seule catégorie, ce qui a provoqué des problèmes : le dictionnaire ne peut pas être construit à cause d'une taille limitée de mots clés et en même temps du paramètrage assez haut `no_below`.

    Alors lorsque la durée est fixé à 15 jours, l'analyse fonctionne.

2. Les mots polluants : à part des mots grammaticaux, il existe toujours des mots polluants, tels que `janvier`, ou `faire` dans la catégorie `VERB`, qui ne peuvent pas être supprimés en choisissant la catégorie. Ainsi, on le laisse côté ou faut-il créer une liste de stop-words ?

***
## 29 avril 2023 ##
**CHENG** : 

Tâches : 

- Améliorer le script `run_lda` pour atteindre notre objectif d'anlayse du corpus. 
- Résoudre les problèmes rencontrés lors de l'exécution du script `run_lda`
- Séparation du corpus par ***trimestre*** (3 mois) pour que nous puissions réaliser les analyses du texte suivantes.

Après la discussion en groupe, nous avons temporairement décidé de diviser le corpus en **trimestres distincts**. D'un côté, nous souhaitons analyser les textes en fonction des caractéristiques trimestrielles. D'un autre côté, en divisant le corpus en quatre parties, nous réduisons le nombre de traitements de documents (4 au total). Toutefois, il y a aussi des inconvénients à cette approche, car la génération du corpus en format XML ou JSON avec le script "extraire_many" prend beaucoup de temps à chaque fois (environ 12 heures pour traiter 3 mois de données TXT).


Basée sur le script `extraire_many` (qui a été ajouté des arguments `-f format` et `-p outil de traitement`) que mes camarades ont déjà modifié, j'ai essayé d'exécuter le script et modifier le script `run_lda`. Mais j'ai trouvé que les ponctuations sont aussi analysées selon ce script. J'ai donc spécifié les catégories grammaticales à analyser : Noun,V, ADJ, ADV, PROPN, etc. 

***
# *Travaux du projet en commun*
## 14 mai 2023

Pour finaliser notre projet, nous avons enfin déterminé notre propre manière de traiter le corpus `RSS` . Parmi toutes les catégories des news, nous avons choisi d'étudier trois thématiques qui sont plus ou moins relatives à la domaine *culture et art* - `culture` `livres` `cinéma`. 

En ce qui concerne la constitution du corpus, chacun d'entre nous a d'abord pris une des trois catégories spécifiques. En lancant le programme `extraire_many,py`, on a obtenu à la fin 12 fichiers xml qui correspondent aux données de tous les trisemestres de l'année pour trois catégories. Après avoir joué sur les paramètres du modèle LDA, nous avons pu faire des analyses des motifs sur les résultats de visualistion LDA.

***
## 15 mai 2023
**Problèmes rencontrés** : 
- L'exécution du script `extraire_many` prend beaucoup de temps lorsqu'il traite les données du format TXT vers le format XML. Il semble y avoir des problèmes dans ce code, et il est nécessaire de les résoudre.
- La caractéristique et les similitudes des 30 mots les plus fréquents identifiés par le modèle LDA ne sont pas suffisamment évidentes. Il y a de nombreux mots ambiguës qui ne sont pas nécessairement liés à la catégorie que nous avons sélectionnée.

***
## 16/17 mai 2023
Nous avons modifié notre script en fonction du script donné par notre enseignants qui semble plus logique car il diminu maximal le temps d'exécution. De pas mal dplus,

- Nous avons upload tous les corpus générés dans les nouveaux dossierx créé de la branche `main`: 
1. Dossier **`corpus`** : Les xmls du sujet éco-politique : catégorie politique, une, international.
2. DOssier **`CORPUS_cineculart`** : Les xmls du sujet artistique qui comprend la catégorie cinéma, art et culture.


