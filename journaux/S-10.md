# Séance 10

## 12 avril 2023
**HUANG** : Cette séance est consacrée au TP. Après avoir récupéré les scripts renouvelés sur le git du prof, j'ai découvert la structure spécifique pour l'analyse syntaxique. Vu que le script d'annotation du module `Stanza` n'est pas disponible comme celui de `Spacy` et `trankit`, mais les structures de ces scripts se ressemblent beaucoup (avec juste des modification des applications spécifiques), j'ai créé un script *analyse_st.py* qui imite la structure de deux autres analyses dédié à l'application de `Stanza`. Ce script est maintenant disponible sur la branche **hyd-s10**, avec un exemple de produit *sortie.json*, qui utilise l'analyseur `Stanza` en prenant en compte deux catégories de nouvelles.

## 13 avril 2023
**HUANG** : J'ai procédé à l'exercice 2 du TP. Pour la question 1 et 2, les commentaires ainsi que les consignes sur le site m'ont donné un concept assez clair de la fonction du script *run_lda.py*. Quant à changer l'entrée pour notre propre fichier, j'ai réussi à le remplacer par un fichier xml (exemple donné par le prof : `test.xml`). Mais pour json, ça me paraît étrange de ne rien capturer depuis mon fichier json, ce qui demande certainement une modification de code.

Ainsi, pour la question 3, je l'ai réalisé en basant sur la forme `xml`. Il est clair que certains paramères peuvent être transformé à des arguments à l'aide du module `argparse` :
```
num_topics = 10
chunksize = 2000
passes = 20
iterations = 400
eval_every = None

```
Ces paramètres peuvent notamment modifiés selon notre besoin, et je les ai transformés des chiffres absolus à des arguments (avec défaut) dans le script.

Toujours pour la question 3, afin de choisir l'entrée (même si j'ai pas encore arrivée à traiter les fichiers json), l'entrée est également transformée à un *argument nécessaire* :
```
input_file = args.input_file
docs = list(extract_documents(input_file))
```

**CHENG** : J'ai télécharger les codes déposés par le prof et j'ai commencé à corriger mes scripts précédents. Par rapport au TP de cette semaine, je suis en train de réfléchir comment le faire. Mais je n'ai pas bien compris les tâches de ce TP pour l'instant.

***

## 16 avril 2023
**ZHANG**： conformément aux scripts uploadés par le prof, j'ai tout simplement changé quelques lignes de codes, tels que l'ajout de l'option *-f* renvoyant au format d'export. J'ai à nouveau créé le script **export_pickle.py** afin de nous diriger vers la gestion de `pickle`. J'ai renouvelé et réorganisé le contenu de ma branhce `zxh-s10`.

**CHENG** : 


## 17 avril 2023
**ZHANG**: J'ai essayé de comprendre le script **run_lda.py**. L'idée principale est de tester la méthode non-supervisé `LDA` en important notre propre corpus pour renovyer automatiquement les thématiques des textes dont le nombre peut se limiter par humain. Voici les étapes à suivre:

```
Prétraiter les documents : les convertir en minuscules, les segmenter en mots, supprimer les chiffres et les mots d'un seul caractère, et les normaliser en forme de base.
Calculer les bigrammes et les ajouter aux données d'origine.
Supprimer les termes avec une fréquence de document trop faible ou trop élevée et créer un dictionnaire.
Convertir les documents en vecteurs de sacs de mots.
Former le modèle LDA et ajuster les paramètres tels que le nombre de sujets, la taille des blocs et les itérations d'entraînement.
Calculer la cohérence des sujets, afficher la cohérence moyenne des sujets et imprimer les sujets par ordre de cohérence.
```
Pourtant, ce qui me confuse, c'est que la facon de parvernir à la corrélation du modèle avec notre projet. Je vais juste tenter de faire cela.